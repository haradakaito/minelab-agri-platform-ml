{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 信号処理用ノートブック"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csi/minelab-agri-platform-ml/.venv/lib/python3.10/site-packages/tslearn/bases/bases.py:15: UserWarning: h5py not installed, hdf5 features will not be supported.\n",
      "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
      "  warn(h5py_msg)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "from tslearn.clustering import KShape\n",
    "\n",
    "from lib import Util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 設定ファイルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定ファイルの読み込み\n",
    "with open(f\"{Util.get_root_dir()}/../config/config.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信号処理パイプライン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalProcessor:\n",
    "    \"\"\"信号処理クラス\"\"\"\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def remove_all_zero_col(self, inplace:bool=False):\n",
    "        \"\"\"全て0の列を削除\"\"\"\n",
    "        try:\n",
    "            df = self.df.copy()\n",
    "\n",
    "            # 全て0の列を削除\n",
    "            for col in df.columns:\n",
    "                if (df[col] == 0).all():\n",
    "                    df = df.drop(col, axis=1)\n",
    "\n",
    "            # inplace=Trueの場合は元のdfを更新\n",
    "            if inplace:\n",
    "                self.df = df\n",
    "                return self.df\n",
    "            else:\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def remove_all_value_col(self, inplace:bool=False):\n",
    "        \"\"\"全て同じ値の列を削除\"\"\"\n",
    "        try:\n",
    "            df = self.df.copy()\n",
    "\n",
    "            # 全て同じ値の列を削除\n",
    "            for col in df.columns:\n",
    "                if len(df[col].unique()) == 1:\n",
    "                    df = df.drop(col, axis=1)\n",
    "\n",
    "            # inplace=Trueの場合は元のdfを更新\n",
    "            if inplace:\n",
    "                self.df = df\n",
    "                return self.df\n",
    "            else:\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def hampel_filter(self, window_size:int=5, alpha:float=3.0, inplace:bool=False):\n",
    "        \"\"\"hampelフィルターを全ての列に適用\"\"\"\n",
    "        try:\n",
    "            df = self.df.copy()\n",
    "\n",
    "            # hampelフィルターを全ての列に適用\n",
    "            for col in df.columns:\n",
    "                df[col] = self._hampel_filter_col(df[col].values, window_size, alpha)\n",
    "\n",
    "            # inplace=Trueの場合は元のdfを更新\n",
    "            if inplace:\n",
    "                self.df = df\n",
    "                return self.df\n",
    "            else:\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def _hampel_filter_col(self, array:np.ndarray, window_size:int, alpha:float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Hampelフィルター\n",
    "\n",
    "        params\n",
    "        ------\n",
    "        array: np.ndarray\n",
    "            フィルターをかける配列\n",
    "        window_size: int\n",
    "            ウィンドウサイズ\n",
    "        alpha: float\n",
    "            閾値\n",
    "\n",
    "        return\n",
    "        ------\n",
    "        np.ndarray\n",
    "            フィルター後の配列\n",
    "        \"\"\"\n",
    "        new_array   = array.copy()   # フィルター後の配列\n",
    "        n           = len(array)     # 配列の長さ\n",
    "        half_window = window_size//2 # ウィンドウサイズの半分\n",
    "\n",
    "        # 各要素についてフィルターをかける\n",
    "        for i in range(n):\n",
    "            # ウィンドウの範囲を取得\n",
    "            start  = max(0, i-half_window)   # 0以下にならないようにmaxを取る\n",
    "            end    = min(n, i+half_window+1) # n以上にならないようにminを取る\n",
    "            kernel = array[start:end]        # ウィンドウの範囲を取得\n",
    "\n",
    "            # 中央値と尺度統計量を計算\n",
    "            median = np.median(kernel)                 # 中央値\n",
    "            mad    = np.median(np.abs(kernel-median))  # MAD (中央値絶対偏差)\n",
    "            std    = 1.4826*mad                        # Hampelフィルターのスケールファクター\n",
    "\n",
    "            # 外れ値の検出と置き換え\n",
    "            if np.abs(array[i]-median) > alpha*std:\n",
    "                new_array[i] = median\n",
    "        return new_array\n",
    "\n",
    "    def difference_filter(self, stride:int=1, inplace:bool=False):\n",
    "        \"\"\"差分フィルター\"\"\"\n",
    "        try:\n",
    "            df = self.df.copy()\n",
    "\n",
    "            # 差分フィルター\n",
    "            df = df.diff(stride)\n",
    "            df = df.dropna(axis=0)\n",
    "            df = df.reset_index(drop=True)\n",
    "\n",
    "            # inplace=Trueの場合は元のdfを更新\n",
    "            if inplace:\n",
    "                self.df = df\n",
    "                return self.df\n",
    "            else:\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def standardize(self, inplace:bool=False):\n",
    "        \"\"\"標準化\"\"\"\n",
    "        try:\n",
    "            df = self.df.copy()\n",
    "\n",
    "            # 標準化\n",
    "            df = (df - df.mean()) / df.std()\n",
    "\n",
    "            # inplace=Trueの場合は元のdfを更新\n",
    "            if inplace:\n",
    "                self.df = df\n",
    "                return self.df\n",
    "            else:\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def kshape_clustering(self, n_clusters:int=1, inplace:bool=False):\n",
    "        \"\"\"KShapeクラスタリング\"\"\"\n",
    "        try:\n",
    "            df = self.df.copy()\n",
    "\n",
    "            # KShapeクラスタリング\n",
    "            kshape = KShape(n_clusters=n_clusters, random_state=3407)\n",
    "            kshape_base = kshape.fit(df.T.values)\n",
    "            cnt = collections.Counter(kshape_base.labels_)\n",
    "            cluster_labels_KS = {}\n",
    "            for k in cnt:\n",
    "                cluster_labels_KS['cluster-{}'.format(k)] = cnt[k]\n",
    "            centroids = pd.DataFrame()\n",
    "            for i in range(len(kshape_base.cluster_centers_)):\n",
    "                centroids = pd.concat([centroids, pd.Series(kshape_base.cluster_centers_[i].reshape(len(kshape_base.cluster_centers_[i])))], axis=1)\n",
    "\n",
    "            # inplace=Trueの場合は元のdfを更新\n",
    "            if inplace:\n",
    "                self.df = centroids\n",
    "                return self.df\n",
    "            else:\n",
    "                return centroids\n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信号処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共通ファイルを取得\n",
    "common_file = Util.get_common_files(path_list=[f\"{Util.get_root_dir()}/../data/csv-data/{field_device}/amp/\" for field_device in config[\"FieldDevice\"][\"Pcap\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.32it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.31it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.27it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# 各ファイルに対して信号処理を適用\n",
    "for field_device in sorted(config[\"FieldDevice\"][\"Pcap\"]):\n",
    "    for file_name in tqdm(common_file):\n",
    "        # ファイルのパスを取得\n",
    "        file_path = f\"{Util.get_root_dir()}/../data/csv-data/{field_device}/amp/{file_name}\"\n",
    "        # データを読み込み（TimeカラムをIndexに設定）\n",
    "        df = pd.read_csv(file_path, index_col=0).set_index(\"Time\", drop=True)\n",
    "\n",
    "        # 信号処理を適用\n",
    "        sp = SignalProcessor(df)\n",
    "        ## 全て0の列を削除\n",
    "        sp.remove_all_zero_col(inplace=True)\n",
    "        ## hampelフィルターを適用\n",
    "        sp.hampel_filter(inplace=True)\n",
    "        ## 全て同じ値の列を削除\n",
    "        sp.remove_all_value_col(inplace=True)\n",
    "        ## 標準化\n",
    "        sp.standardize(inplace=True)\n",
    "\n",
    "        # データを保存\n",
    "        Util.create_path(f\"{Util.get_root_dir()}/../data/preprocessed-data/{field_device}/amp/\")\n",
    "        sp.df.to_csv(f\"{Util.get_root_dir()}/../data/preprocessed-data/{field_device}/amp/{file_name}\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
